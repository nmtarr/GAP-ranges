{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worm-eating Warbler - TWS2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Setup  \n",
    "Fill out the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_id = 'tws2019'\n",
    "gap_id = 'bwewax'\n",
    "wsw_id = 'bwewax0'\n",
    "sci_name = 'Worm-eating Warbler'\n",
    "notebook_name = gap_id + eval_id + \".ipynb\"\n",
    "summary_name = 'wormie1' # an short, memorable name to use for file names etc.\n",
    "codeDir = '/users/nmtarr/code/GAP-range-evaluation/'\n",
    "inDir = '/users/nmtarr/documents/GAP_Ranges/inputs/'\n",
    "outDir = '/users/nmtarr/documents/GAP_Ranges/outputs/'\n",
    "eval_db = outDir + gap_id + eval_id + '.sqlite'\n",
    "request_id = \"GBIFr14\"\n",
    "filter_id = \"GBIFf4\"\n",
    "occ_db = '/users/nmtarr/documents/occurrence_records/outputs/{0}{1}{2}.sqlite'.format(wsw_id, request_id, filter_id)\n",
    "wsw_db = '/users/nmtarr/code/occurrence-records-wrangler/parameters.sqlite'\n",
    "parameters_db = '/users/nmtarr/code/GAP-range-evaluation/evaluations.sqlite'\n",
    "shucs_loc = '/users/nmtarr/data/SHUCS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pprint\n",
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "pd.set_option('display.width', 600)\n",
    "pd.set_option('display.max_colwidth', 60)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from IPython.display import Image\n",
    "import repo_functions as functions\n",
    "from pygbif import occurrences\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Parameters\n",
    "\n",
    "Evaluation parameters need to be set and justified in the cells within this section.  Values that are entered here will be used to update cells within the 'evaluations' table stored in evaluations.sqlite. The decisions about what values to use are primarily documented here, not in the evaluations database.\n",
    "\n",
    "Note that the evaluation ID and species' GAP code are set in the cell above, not below.  I am proposing that evaluation parameter sets also be documented as unique entities in a database (i.e, evaluations.sqlite).  Each evaluation can be given a unique id that can be used in documentation, file naming, and for the names of the columns that will be added to the GAP range table to record the results of the evaluation.  In this example, the evaluation_id is __tws2019__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sets = \"{0}, {1}\".format(request_id, filter_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years\n",
    "Justification: A fair number of records exist for this species, so I chose 2 old years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = \"2001, 2002\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Months\n",
    "Justification: The species does not winter in the US, so only summer months are relevant.  The choice in months was informed by the Birds of North America online species account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = \"5,6,7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Method\n",
    "Justification: The restrictive nature of \"proportion in polygon\" is a good fit for the demonstration of the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"proportion in polygon\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum Count\n",
    "Justification: This species is fairly easy to identify, but misidentification could be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Tolerance\n",
    "Justification: The species is not super-abundant and is uncommon in many places, but not rare.  40% chance of error seems pretty liberal at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_tolerance = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = \"Nathan Tarr\"\n",
    "date = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "justification = \"See \" + notebook_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = \"\"\"For development\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to evaluations.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connjup = sqlite3.connect(parameters_db)\n",
    "cursorjup = connjup.cursor()\n",
    "\n",
    "# Make a row for species-evaluation\n",
    "sqlrow = \"\"\"INSERT OR IGNORE INTO evaluations (\"evaluation_id\", \"species_id\") VALUES (?, ?);\"\"\"\n",
    "vals = [eval_id, gap_id]\n",
    "cursorjup.execute(sqlrow, vals)\n",
    "\n",
    "# Filter sets\n",
    "sqlfilters = \"\"\"UPDATE evaluations SET filter_sets=? WHERE evaluation_id=? AND species_id=?;\"\"\"\n",
    "vals = [filter_sets, eval_id, gap_id]\n",
    "cursorjup.execute(sqlfilters, vals)\n",
    "\n",
    "# Years\n",
    "sqlyear = \"\"\"UPDATE evaluations SET years=? WHERE evaluation_id=? AND species_id=?;\"\"\"\n",
    "vals = [years, eval_id, gap_id]\n",
    "cursorjup.execute(sqlyear, vals)\n",
    "\n",
    "# Months\n",
    "sqlmonths = \"\"\"UPDATE evaluations SET months=? WHERE evaluation_id=? AND species_id=?;\"\"\"\n",
    "vals = [months, eval_id, gap_id]\n",
    "cursorjup.execute(sqlmonths, vals)\n",
    "\n",
    "# Evaluation Method\n",
    "sqlmethod = \"\"\"UPDATE evaluations SET method=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [method, eval_id, gap_id]\n",
    "cursorjup.execute(sqlmethod, vals)\n",
    "\n",
    "# Minimum Count\n",
    "sqlmin = \"\"\"UPDATE evaluations SET min_count=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [min_count, eval_id, gap_id]\n",
    "cursorjup.execute(sqlmin, vals)\n",
    "\n",
    "# Error Tolerance\n",
    "sqltolerance = \"\"\"UPDATE evaluations SET error_tolerance=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [error_tolerance, eval_id, gap_id]\n",
    "cursorjup.execute(sqltolerance, vals)\n",
    "\n",
    "# Justification\n",
    "sqljust = \"\"\"UPDATE evaluations SET justification=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [justification, eval_id, gap_id]\n",
    "cursorjup.execute(sqljust, vals)\n",
    "\n",
    "# Credits\n",
    "sqlcreator = \"\"\"UPDATE evaluations SET creator=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [creator, eval_id, gap_id]\n",
    "cursorjup.execute(sqlcreator, vals)\n",
    "\n",
    "# Notes\n",
    "sqlnotes = \"\"\"UPDATE evaluations SET notes=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [notes, eval_id, gap_id]\n",
    "cursorjup.execute(sqlnotes, vals)\n",
    "\n",
    "sqldate= \"\"\"UPDATE evaluations SET date=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [date, eval_id, gap_id]\n",
    "cursorjup.execute(sqldate, vals)\n",
    "\n",
    "connjup.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Parameters\n",
    "Display the record that was just written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation_id                         tws2019\n",
      "species_id                             bwewax\n",
      "years                              2001, 2002\n",
      "months                                  5,6,7\n",
      "min_count                                   1\n",
      "error_tolerance                            40\n",
      "method                  proportion in polygon\n",
      "filter_sets                   GBIFr14, GBIFf4\n",
      "justification         See bwewaxtws2019.ipynb\n",
      "creator                           Nathan Tarr\n",
      "date               2019-08-15 08:12:07.295704\n",
      "notes                         For development\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_sql_query(sql=\"SELECT * FROM evaluations WHERE evaluation_id='{0}' AND species_id='{1}'\".format(eval_id, gap_id), con=connjup)\n",
    "print(df1.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request Filter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request_id                                                          GBIFr14\n",
      "source                                                                 GBIF\n",
      "lat_range                                                             27,41\n",
      "lon_range                                                           -91,-75\n",
      "years_range                                                       2000,2002\n",
      "months_range                                                           1,12\n",
      "geoissue                                                              False\n",
      "coordinate                                                             True\n",
      "continent                                                              None\n",
      "creator                                                             N. Tarr\n",
      "notes           For evaluating 2001 GAP range maps.  Are the years correct?\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "filterconn = sqlite3.connect(wsw_db)\n",
    "df2 = pd.read_sql_query(sql=\"SELECT * FROM gbif_requests WHERE request_id='{0}'\".format(request_id), con=filterconn)\n",
    "print(df2.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Request Filter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_id                                                                          GBIFf4\n",
      "dataset                                                                              GBIF\n",
      "collection_codes_omit                                                                None\n",
      "institutions_omit                                                                    None\n",
      "has_coordinate_uncertainty                                                              0\n",
      "max_coordinate_uncertainty                                                           5000\n",
      "bases_omit                                            PRESERVED_SPECIMEN, FOSSIL_SPECIMEN\n",
      "protocols_omit                                                                       None\n",
      "sampling_protocols_omit                                                              None\n",
      "issues_omit                   GEODETIC_DATUM_INVALID, INDIVIDUAL_COUNT_INVALID, MULTIM...\n",
      "creator                                                                           N. Tarr\n",
      "notes                                                                                None\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_sql_query(sql=\"SELECT * FROM gbif_filters WHERE filter_id = '{0}'\".format(filter_id), con=filterconn)\n",
    "print(df2.loc[0])\n",
    "filterconn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occurrence Record Retrieval and Display\n",
    "This repo is dependent upon the occorrence-records-wrangler repo because occurrence data is retrieved here from sqlite occurrence databases generated with the records wrangler repo.  In this section, a connection is established and records are filtered according to the evaluation parameters.  Keep in mind that the occurrence record databases were themselves created with filters so you have to be mindful of how parameters set here compare to ones set there. For example, dates of records included will be determined by whichever process had a more restrictive date range. \n",
    "\n",
    "The first step in using occurrence records to evaluate GAP range is to build a database to hold the GAP 12 digit HUCs, range for the species, and suitable occurrence records.  The database is also suitable for performing the necessary spatial queries.  The GAP range is retrieved from ScienceBase and the HUCs would be too if they were available as a shapefile.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.make_evaluation_db(eval_db=eval_db, gap_id=gap_id, shucLoc=shucs_loc, inDir=inDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy records to the evaluation database, filtering out records from months or years that aren't wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the evaluation occurrence records database\n",
    "evconn = sqlite3.connect(eval_db)\n",
    "os.putenv('SPATIALITE_SECURITY', 'relaxed')\n",
    "evconn.enable_load_extension(True)\n",
    "cursor = evconn.cursor()\n",
    "cursor.executescript(\"\"\"SELECT load_extension('mod_spatialite');\"\"\")\n",
    "\n",
    "# Attach occurrence database\n",
    "cursor.execute(\"ATTACH DATABASE ? AS occs;\", (occ_db,))\n",
    "\n",
    "# Create table of occurrences that fit within evaluation parameters\n",
    "years = tuple([x.strip() for x in years.split(',')])\n",
    "months = tuple([x.strip().zfill(2) for x in months.split(',')])\n",
    "cursor.execute(\"\"\"CREATE TABLE evaluation_occurrences AS \n",
    "                   SELECT * FROM occs.occurrences \n",
    "                   WHERE STRFTIME('%Y', OccurrenceDate) IN {0} \n",
    "                       AND STRFTIME('%m', OccurrenceDate) IN {1};\"\"\".format(years, months))\n",
    "\n",
    "# Export occurrence circles as a shapefile (all seasons)\n",
    "cursor.execute(\"\"\"SELECT RecoverGeometryColumn('evaluation_occurrences', 'circle_wgs84', \n",
    "                  4326, 'POLYGON', 'XY');\"\"\")\n",
    "\n",
    "sql = \"\"\"SELECT ExportSHP('evaluation_occurrences', 'circle_wgs84', ?, 'utf-8');\"\"\"\n",
    "subs = outDir + summary_name + \"_circles\"\n",
    "cursor.execute(sql, (subs,))\n",
    "\n",
    "# Export occurrence 'points' as a shapefile (all seasons)\n",
    "cursor.execute(\"\"\"SELECT RecoverGeometryColumn('evaluation_occurrences', 'geom_xy4326', \n",
    "                  4326, 'POINT', 'XY');\"\"\")\n",
    "subs = outDir + summary_name + \"_points\"\n",
    "cursor.execute(\"\"\"SELECT ExportSHP('evaluation_occurrences', 'geom_xy4326', ?, 'utf-8');\"\"\", (subs,))\n",
    "\n",
    "# Close db\n",
    "evconn.commit()\n",
    "evconn.close()\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Occurrence Points and GAP Range Map\n",
    "Get the GAP range map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://www.sciencebase.gov/catalog/file/get/59f5ebb4e4b063d5d307e0d1?f=__disk__1c%2F00%2F75%2F1c00755f339c97bafe6c9d1c69ee14cef5326d7c to /users/nmtarr/documents/GAP_Ranges/inputs/bWEWAx_CONUS_Range_2001v1.zip\n",
      "downloading https://www.sciencebase.gov/catalog/file/get/59f5ebb4e4b063d5d307e0d1?f=__disk__7c%2F1d%2Fc7%2F7c1dc7208c25d4ed06614642f32dbac70c2aa2d5 to /users/nmtarr/documents/GAP_Ranges/inputs/bWEWAx_CONUS_Range_2001v1.xml\n"
     ]
    }
   ],
   "source": [
    "gap_range = functions.download_GAP_range_CONUS2001v1(gap_id, inDir)\n",
    "\n",
    "# Reproject the GAP range to WGS84 and export to shapefile for displaying\n",
    "conn3 = sqlite3.connect(':memory:')\n",
    "os.putenv('SPATIALITE_SECURITY', 'relaxed')\n",
    "conn3.enable_load_extension(True)\n",
    "cursor3 = conn3.cursor()\n",
    "sql_repro = \"\"\"\n",
    "SELECT load_extension('mod_spatialite');\n",
    "\n",
    "SELECT InitSpatialMetadata(1);\n",
    "\n",
    "SELECT ImportSHP('{0}{1}_conus_range_2001v1', 'rng3', 'utf-8', 5070,\n",
    "                 'geom_5070', 'HUC12RNG', 'MULTIPOLYGON');\n",
    "\n",
    "CREATE TABLE rng2 AS SELECT HUC12RNG, seasonCode, seasonName,\n",
    "                            Transform(geom_5070, 4326) AS geom_4326 FROM rng3;\n",
    "\n",
    "SELECT RecoverGeometryColumn('rng2', 'geom_4326', 4326, 'MULTIPOLYGON', 'XY');\n",
    "\n",
    "SELECT ExportSHP('rng2', 'geom_4326', '{0}{1}_range_4326', 'utf-8');\n",
    "\"\"\".format(inDir, gap_id)\n",
    "\n",
    "cursor3.executescript(sql_repro)\n",
    "conn3.close()\n",
    "del cursor3\n",
    "\n",
    "gap_range2 = \"{0}{1}_range_4326\".format(inDir, gap_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display occurrence records over GAP range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shp1 = {'file': gap_range2, 'column': None, 'alias': 'GAP range map',\n",
    "        'drawbounds': False, 'linewidth': .5, 'linecolor': 'y',\n",
    "        'fillcolor': 'y', 'marker':'s'}\n",
    "\n",
    "shp2 = {'file': '{0}{1}_circles'.format(outDir, summary_name), 'column': None,\n",
    "        'alias': 'Occurrence records', 'drawbounds': True, 'linewidth': .75, 'linecolor': 'k',\n",
    "        'fillcolor': None, 'marker':'o'}\n",
    "\n",
    "# Display occurrence polygons\n",
    "title=\"{1} ({0})\".format(years, sci_name)\n",
    "functions.MapShapefilePolygons(map_these=[shp1, shp2], title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAP Known Range Data Evaluation\n",
    "With all the data in a sqlite database with spatialite capabilities, we can perform the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no such column: species_id\n"
     ]
    }
   ],
   "source": [
    "functions.evaluate_GAP_range(eval_id=eval_id, gap_id=gap_id, eval_db=eval_db, occs_db=occ_db,\n",
    "                             outDir=outDir, codeDir=codeDir, method='Proportion in polygon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT strHUC12RNG AS HUC12RNG, intGAPOrigin AS Origin, intGAPPresence AS Presence, intGAPReproduction AS Reproduction,intGAPSeason AS Season, eval_cnt, eval, validated_presence AS validated_pres FROM new_range WHERE eval_cnt >=0': no such table: new_range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/range_eval/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: new_range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-df8df87f541c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0;34m\"intGAPReproduction AS Reproduction,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0;34m\"intGAPSeason AS Season, eval_cnt, eval, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                     \"validated_presence AS validated_pres FROM new_range WHERE eval_cnt >=0\", con=connr)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HUC12RNG\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tabular results of the evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/range_eval/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    312\u001b[0m     return pandas_sql.read_query(\n\u001b[1;32m    313\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         parse_dates=parse_dates, chunksize=chunksize)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/range_eval/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/range_eval/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \"Execution failed on sql '{sql}': {exc}\".format(\n\u001b[1;32m   1444\u001b[0m                     sql=args[0], exc=exc))\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/range_eval/lib/python3.6/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;31m# this version of raise is a syntax error in Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/range_eval/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT strHUC12RNG AS HUC12RNG, intGAPOrigin AS Origin, intGAPPresence AS Presence, intGAPReproduction AS Reproduction,intGAPSeason AS Season, eval_cnt, eval, validated_presence AS validated_pres FROM new_range WHERE eval_cnt >=0': no such table: new_range"
     ]
    }
   ],
   "source": [
    "connr = sqlite3.connect(eval_db)\n",
    "df4 = pd.read_sql_query(sql=\"SELECT strHUC12RNG AS HUC12RNG, \"\n",
    "                                    \"intGAPOrigin AS Origin, intGAPPresence AS Presence, \"\n",
    "                                    \"intGAPReproduction AS Reproduction,\"\n",
    "                                    \"intGAPSeason AS Season, eval_cnt, eval, \"\n",
    "                                    \"validated_presence AS validated_pres FROM new_range WHERE eval_cnt >=0\", con=connr)\n",
    "df4.set_index([\"HUC12RNG\"], inplace=True)\n",
    "print(\"Tabular results of the evaluation\")\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Mapped results of the evaluation.\")\n",
    "shp3 = {'file': '{0}{1}_eval'.format(outDir, gap_id), 'column': 'eval_gbif1',\n",
    "        'alias': 'eval_gbif1', 'column_colors': {1: 'b', 0: 'r'}, \n",
    "        'value_alias': {1:'Agreement', 0:'Disagreement'}, 'drawbounds': False, \n",
    "        'marker': \"s\"}\n",
    "title=\"Worm-eating Warbler -- eval\"\n",
    "functions.MapShapefilePolygons(map_these=[shp1, shp3], title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups0 = occonn.execute(\"SELECT COUNT(occ_id) FROM occurrences GROUP BY geom_xy4326, occurrenceDate;\").fetchall()\n",
    "dups1 = [x[0] for x in dups0]\n",
    "dups2 = [x for x in dups1 if x > 1]\n",
    "print(str(len(dups2)) + ' records were duplicates based on xy coordinate and date-time')\n",
    "\n",
    "# Close db connection\n",
    "occonn.close()\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After occurrence circles are attributed to HUCs, the results can be recorded in the species' range map table in terms of whether the two data sets agreed and whether they validate the GAP range data for any HUCs. For each evaluation, a column is added for 1) how many records could be attributed to each huc and 2) whether there is agreement at that huc (1 for yes, 0 for no, 'None' for no data for that huc) and 3) whether the GAP range has been validated by the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many records were available in the occurrence database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(eval_db)\n",
    "cursor = conn.cursor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of the records were attributable to a HUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hucable = curs_rng.execute(\"SELECT SUM(eval_gbif1_cnt) FROM new_range WHERE eval_gbif1_cnt >=0\").fetchall()[0]\n",
    "print(str(hucable[0]) + \" records were attributable to a HUC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many hucs had records attributed to them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = curs_rng.execute(\"SELECT COUNT(eval_gbif1_cnt) FROM new_range WHERE {0}_cnt >=0\".format(eval_id)).fetchall()[0]\n",
    "print(str(containers[0]) + \" HUCs 'contained' records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many records were not used because of the minimum count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_rng = sqlite3.connect(outDir + gap_id + '_range.sqlite')\n",
    "curs_rng = conn_rng.cursor()\n",
    "ones = curs_rng.execute(\"SELECT SUM(eval_gbif1_cnt) FROM new_range WHERE eval_gbif1_cnt = 1\").fetchall()[0]\n",
    "print(str(ones[0]) + \" HUCs had occurrences but were not validated because they didn't meet the minimum.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many HUCs were validated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated = curs_rng.execute(\"SELECT COUNT(eval_gbif1) FROM new_range WHERE {0} = 1\".format(eval_id)).fetchall()[0]\n",
    "print(str(validated[0]) + \" HUCs were validated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many HUCs did GAP appear to omit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = curs_rng.execute(\"SELECT COUNT(eval_gbif1) FROM new_range WHERE {0} = 0\".format(eval_id)).fetchall()[0]\n",
    "print(str(missed[0]) + \" HUCs were missed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What was the maximum number of occurrences attributable to a single HUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = curs_rng.execute(\"SELECT MAX(eval_gbif1_cnt) FROM new_range\").fetchall()[0]\n",
    "print(\"The maximum number of records attributed to a HUC was \" + str(maxi[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "This is just a starting point that needs scrutiny.  It is currently hard-coded for a single species, so deploying it would require redesigning to accomodate large numbers of species, multiple users, many more occurrence records, optimal methods for evaluation and range delineation among other things.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
