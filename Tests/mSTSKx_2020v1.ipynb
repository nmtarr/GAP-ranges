{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Name - Evaluation code\n",
    "Author: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill out the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_id = '2020v1'\n",
    "notebook_name = \"mSTSKx_2020v1.ipynb\"\n",
    "summary_name = 'stsk_r' # a short, memorable name to use for file names etc.\n",
    "\n",
    "# Paths to occurrence record databases to use (from wildlife-wrangler).  Put paths as items in a tuple.\n",
    "recent_dbs = ('P:/Proj3/USGap/Vert/USranges/2020v1/OccRecords/mstskx0GBIFr25GBIFf10.sqlite',)\n",
    "historic_dbs = ('P:/Proj3/USGap/Vert/USranges/2020v1/OccRecords/mstskx0GBIFr26GBIFf10.sqlite',)\n",
    "\n",
    "codeDir = 'T:/code/GAP-ranges/'\n",
    "inDir = 'P:/Proj3/USGap/Vert/USRanges/2020v1/2001Ranges/'\n",
    "outDir = 'P:/Proj3/USGap/Vert/USRanges/2020v1/Results/'\n",
    "parameters_db = 'P:/Proj3/USGap/Vert/DBase/ranges-records.sqlite'\n",
    "shucs_loc = 'P:/Proj3/USGap/Vert/Model/data/HucRng/Hucs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a bug with mpl_toolkits, the following code is a temp fix, hopefully. https://stackoverflow.com/questions/52911232/basemap-library-using-anaconda-jupyter-notebooks-keyerror-proj-lib/54087410#54087410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJ_LIB'] = r'c:\\Users\\nmtarr\\AppData\\Local\\Continuum\\miniconda3\\envs\\wrangler\\Library\\share'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Setup  -  Nothing to fill out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pprint\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 600)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from IPython.display import Image\n",
    "import os\n",
    "os.chdir(codeDir)\n",
    "import range_functions as functions\n",
    "os.chdir(outDir)\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['PROJ_LIB'] = r'c:\\Users\\nmtarr\\AppData\\Local\\Continuum\\miniconda3\\envs\\wrangler\\Library\\share'\n",
    "from datetime import datetime\n",
    "t1 = datetime.now()\n",
    "connName = sqlite3.connect(recent_dbs[0])\n",
    "gap_id = connName.execute(\"\"\"SELECT value FROM species_concept WHERE attribute = \"gap_id\";\"\"\").fetchone()[0]\n",
    "common_name = connName.execute(\"\"\"SELECT value FROM species_concept WHERE attribute = \"common_name\";\"\"\").fetchone()[0]\n",
    "sci_name = connName.execute(\"\"\"SELECT value FROM species_concept WHERE attribute = \"scientific_name\";\"\"\").fetchone()[0]\n",
    "del connName\n",
    "eval_db = outDir + gap_id + eval_id + '.sqlite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Parameters\n",
    "\n",
    "Evaluation parameters need to be set and justified in the cells within this section.  Values that are entered here will be used to update cells within the 'evaluations' table stored in evaluations.sqlite. The decisions about what values to use are primarily documented here, not in the evaluations database.\n",
    "\n",
    "Note that the evaluation ID and species' GAP code are set in the cell above, not below.  I am proposing that evaluation parameter sets also be documented as unique entities in a database (i.e, evaluations.sqlite).  Each evaluation can be given a unique id that can be used in documentation, file naming, and for the names of the columns that will be added to the GAP range table to record the results of the evaluation.  In this example, the evaluation_id is __tws2019__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Sets\n",
    "Notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBIFr26, GBIFf10, GBIFr25\n"
     ]
    }
   ],
   "source": [
    "ids = set([])\n",
    "r_s = set([])\n",
    "f_s = set([])\n",
    "occ_dbs = recent_dbs + historic_dbs\n",
    "for db in occ_dbs:\n",
    "    connection = sqlite3.connect(db)\n",
    "    req_id = connection.execute(\"\"\"SELECT DISTINCT request_id FROM occurrences;\"\"\").fetchall()[0]\n",
    "    filt_id = connection.execute(\"\"\"SELECT DISTINCT filter_id FROM occurrences;\"\"\").fetchall()[0]\n",
    "    r_s = r_s | set(req_id)\n",
    "    f_s = f_s | set(filt_id)\n",
    "    ids = ids | set(req_id) | set(filt_id)\n",
    "    del connection\n",
    "filters_request = list(r_s)\n",
    "filters_post = list(f_s)\n",
    "ids = tuple(ids)\n",
    "filter_sets = ids[0]\n",
    "for i in ids[1:]:\n",
    "    filter_sets = filter_sets + ', ' + i\n",
    "print(filter_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years\n",
    "Justification: All available records with somewhat dependable locational information are desired.  GPS became decent around 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2000\n",
    "end_year = 2020\n",
    "years = str(list(range(start_year, end_year + 1, 1)))[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Months\n",
    "Justification: Skunks are not migratory so all months are of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = \"1,2,3,4,5,6,7,8,9,10,11,12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Method\n",
    "Justification: The restrictive nature of \"proportion in polygon\" is a good fit for the demonstration of the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"proportion in polygon\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Tolerance\n",
    "Justification: 20% is a rather modest requirement.  No indication that this species requires anything addressed with this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_tolerance = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = \"Nathan Tarr\"\n",
    "date = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "justification = \"See \" + notebook_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to evaluations.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connjup = sqlite3.connect(parameters_db)\n",
    "cursorjup = connjup.cursor()\n",
    "\n",
    "# Make a row for species-evaluation\n",
    "sqlrow = \"\"\"INSERT OR IGNORE INTO evaluations (\"evaluation_id\", \"species_id\") VALUES (?, ?);\"\"\"\n",
    "vals = [eval_id, gap_id]\n",
    "\n",
    "# Filter sets\n",
    "sqlfilters = \"\"\"UPDATE evaluations SET filter_sets=? WHERE evaluation_id=? AND species_id=?;\"\"\"\n",
    "vals = [filter_sets, eval_id, gap_id]\n",
    "cursorjup.execute(sqlfilters, vals)\n",
    "\n",
    "# Years\n",
    "sqlyear = \"\"\"UPDATE evaluations SET years=? WHERE evaluation_id=? AND species_id=?;\"\"\"\n",
    "vals = [years, eval_id, gap_id]\n",
    "cursorjup.execute(sqlyear, vals)\n",
    "\n",
    "# Months\n",
    "sqlmonths = \"\"\"UPDATE evaluations SET months=? WHERE evaluation_id=? AND species_id=?;\"\"\"\n",
    "vals = [months, eval_id, gap_id]\n",
    "cursorjup.execute(sqlmonths, vals)\n",
    "\n",
    "# Evaluation Method\n",
    "sqlmethod = \"\"\"UPDATE evaluations SET method=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [method, eval_id, gap_id]\n",
    "cursorjup.execute(sqlmethod, vals)\n",
    "\n",
    "# Error Tolerance\n",
    "sqltolerance = \"\"\"UPDATE evaluations SET error_tolerance=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [error_tolerance, eval_id, gap_id]\n",
    "cursorjup.execute(sqltolerance, vals)\n",
    "\n",
    "# Justification\n",
    "sqljust = \"\"\"UPDATE evaluations SET justification=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [justification, eval_id, gap_id]\n",
    "cursorjup.execute(sqljust, vals)\n",
    "\n",
    "# Credits\n",
    "sqlcreator = \"\"\"UPDATE evaluations SET creator=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [creator, eval_id, gap_id]\n",
    "cursorjup.execute(sqlcreator, vals)\n",
    "\n",
    "# Notes\n",
    "sqlnotes = \"\"\"UPDATE evaluations SET notes=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [notes, eval_id, gap_id]\n",
    "cursorjup.execute(sqlnotes, vals)\n",
    "\n",
    "sqldate= \"\"\"UPDATE evaluations SET date=? WHERE evaluation_id=? AND species_id=?\"\"\"\n",
    "vals = [date, eval_id, gap_id]\n",
    "cursorjup.execute(sqldate, vals)\n",
    "\n",
    "connjup.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Parameters\n",
    "Display the record that was just written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation_id                                                                               2020v1\n",
      "species_id                                                                                  mstskx\n",
      "years              2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012...\n",
      "months                                                                  1,2,3,4,5,6,7,8,9,10,11,12\n",
      "min_count                                                                                     None\n",
      "error_tolerance                                                                                 20\n",
      "method                                                                       proportion in polygon\n",
      "filter_sets                                                              GBIFr26, GBIFf10, GBIFr25\n",
      "justification                                                              See mSTSKx_2020v1.ipynb\n",
      "creator                                                                                Nathan Tarr\n",
      "date                                                                    2020-04-20 10:54:18.348801\n",
      "notes                                                                                             \n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_sql_query(sql=\"SELECT * FROM evaluations WHERE evaluation_id='{0}' AND species_id='{1}'\".format(eval_id, gap_id), con=connjup)\n",
    "print(df1.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Set Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                        0\n",
      "request_id                                                                        GBIFr25\n",
      "source                                                                               GBIF\n",
      "lat_range                                                                            None\n",
      "lon_range                                                                            None\n",
      "years_range                                                                     2015,2020\n",
      "months_range                                                                         1,12\n",
      "geoissue                                                                            False\n",
      "coordinate                                                                           True\n",
      "country                                                                                US\n",
      "geometry                                                                             None\n",
      "creator                                                                           N. Tarr\n",
      "notes         Built and used for GAP v2 range map development.  Returns \"recent\" records.\n",
      "                                                                                 0\n",
      "request_id                                                                 GBIFr26\n",
      "source                                                                        GBIF\n",
      "lat_range                                                                     None\n",
      "lon_range                                                                     None\n",
      "years_range                                                              2000,2015\n",
      "months_range                                                                  1,12\n",
      "geoissue                                                                     False\n",
      "coordinate                                                                    True\n",
      "country                                                                         US\n",
      "geometry                                                                      None\n",
      "creator                                                                    N. Tarr\n",
      "notes         Built for GAP v2 range map development.  Returns \"historic\" records.\n",
      "                                                                                              0\n",
      "filter_id                                                                               GBIFf10\n",
      "dataset                                                                                    GBIF\n",
      "institutions_omit                                                                          None\n",
      "collection_codes_omit                                                                      None\n",
      "datasets_omit                                                                              None\n",
      "has_coordinate_uncertainty                                                                    0\n",
      "max_coordinate_uncertainty                                                                 5000\n",
      "bases_omit                                                                      FOSSIL_SPECIMEN\n",
      "sampling_protocols_omit                                                                        \n",
      "issues_omit                 TAXON_MATCH_HIGHERRANK, GEODETIC_DATUM_INVALID, TYPE_STATUS_INVALID\n",
      "duplicates_OK                                                                             False\n",
      "creator                                                                                 N. Tarr\n",
      "notes                                             For use in creating GAP version 2 range maps.\n"
     ]
    }
   ],
   "source": [
    "for db in occ_dbs:\n",
    "    filters2 = filters_request + filters_post\n",
    "    connection = sqlite3.connect(db)\n",
    "    for f in filters2:\n",
    "        try:\n",
    "            set_info = pd.read_sql(sql=\"\"\"SELECT * FROM {0};\"\"\".format(f), con=connection)\n",
    "            set_info = set_info.T.iloc[1:]\n",
    "            set_info.rename({'0': ''}, inplace=True, axis=1)\n",
    "            print(set_info)\n",
    "            filters2.remove(f)\n",
    "        except:\n",
    "            pass\n",
    "    del connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occurrence Record Retrieval and Display\n",
    "This repo is dependent upon the wildlife-wrangler repo because occurrence data is retrieved here from sqlite occurrence databases generated with the records wrangler repo.  In this section, a connection is established and records are filtered according to the evaluation parameters.  Keep in mind that the occurrence record databases were themselves created with filters so you have to be mindful of how parameters set here compare to ones set there. For example, dates of records included will be determined by whichever process had a more restrictive date range. \n",
    "\n",
    "The first step in using occurrence records to evaluate GAP range is to build a database to hold the GAP 12 digit HUCs, range for the species, and suitable occurrence records.  The database is also suitable for performing the necessary spatial queries.  The GAP range is retrieved from ScienceBase and the HUCs would be too if they were available as a shapefile.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.make_evaluation_db(eval_db=eval_db, gap_id=gap_id, shucLoc=shucs_loc, inDir=inDir, outDir=outDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy records to the evaluation database, filtering out records from months or years that aren't wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if len(recent_dbs) == 1:\n",
    "    recent_db = recent_dbs[0]\n",
    "else:\n",
    "    recent_db = functions.concat_dbs(recent_dbs)\n",
    "\n",
    "if len(historic_dbs) == 1:\n",
    "    historic_db = historic_dbs[0]\n",
    "else:\n",
    "    historic_db = functions.concat_dbs(historic_dbs)\n",
    "    \n",
    "# Load records into evaluation database\n",
    "eval_db\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = tuple([x.strip() for x in years.split(',')])\n",
    "months = tuple([x.strip().zfill(2) for x in months.split(',')])\n",
    "for occ_db in occ_dbs:\n",
    "    print(occ_db)\n",
    "    \n",
    "    # Connect to the evaluation occurrence records database\n",
    "    cursor, evconn = functions.spatialite(eval_db)\n",
    "\n",
    "    # Attach occurrence database\n",
    "    cursor.execute(\"ATTACH DATABASE ? AS occs;\", (occ_db,))\n",
    "\n",
    "    # Create table of occurrences that fit within evaluation parameters  --  IF EXISTS JUST APPEND\n",
    "    if occ_db == occ_dbs[0]:\n",
    "        cursor.execute(\"\"\"CREATE TABLE evaluation_occurrences AS \n",
    "                       SELECT * FROM occs.occurrences \n",
    "                       WHERE STRFTIME('%Y', OccurrenceDate) IN {0} \n",
    "                       AND STRFTIME('%m', OccurrenceDate) IN {1};\"\"\".format(years, months))\n",
    "    else:\n",
    "        cursor.execute(\"\"\"INSERT INTO evaluation_occurrences\n",
    "                          SELECT * FROM occs.occurrences \n",
    "                          WHERE STRFTIME('%Y', OccurrenceDate) IN {0} \n",
    "                          AND STRFTIME('%m', OccurrenceDate) IN {1};\"\"\".format(years, months))\n",
    "    \n",
    "# Export occurrence circles as a shapefile (all seasons)\n",
    "cursor.execute(\"\"\"SELECT RecoverGeometryColumn('evaluation_occurrences', 'polygon_4326', \n",
    "                  4326, 'POLYGON', 'XY');\"\"\")\n",
    "sql = \"\"\"SELECT ExportSHP('evaluation_occurrences', 'polygon_4326', ?, 'utf-8');\"\"\"\n",
    "subs = outDir + summary_name + \"_circles\"\n",
    "cursor.execute(sql, (subs,))\n",
    "'''\n",
    "# Export occurrence 'points' as a shapefile (all seasons)\n",
    "cursor.execute(\"\"\"SELECT RecoverGeometryColumn('evaluation_occurrences', 'geom_xy4326', \n",
    "                  4326, 'POINT', 'XY');\"\"\")\n",
    "subs = outDir + summary_name + \"_points\"\n",
    "cursor.execute(\"\"\"SELECT ExportSHP('evaluation_occurrences', 'geom_xy4326', ?, 'utf-8');\"\"\", (subs,))\n",
    "'''\n",
    "# Close db\n",
    "evconn.commit()\n",
    "evconn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Occurrence Points and GAP Range Map\n",
    "A presence shapefile must be created for display because the sciencebase range shapefiles are seasonal, which is not the focus here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_range = functions.download_GAP_range_CONUS2001v1(gap_id, inDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display occurrence records over GAP range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gap_range2 = \"{0}{1}_presence_4326\".format(outDir, gap_id)\n",
    "\n",
    "shp1 = {'file': gap_range2, 'column': None, 'alias': 'GAP range map - presence',\n",
    "        'drawbounds': False, 'linewidth': .5, 'linecolor': 'm',\n",
    "        'fillcolor': 'm', 'marker':'s'}\n",
    "\n",
    "shp2 = {'file': '{0}{1}_circles'.format(outDir, summary_name), 'column': None,\n",
    "        'alias': 'Occurrence records', 'drawbounds': True, 'linewidth': .75, 'linecolor': 'k',\n",
    "        'fillcolor': None, 'marker':'o'}\n",
    "\n",
    "# Display occurrence polygons\n",
    "title=\"{1} ({0})\".format(years[0] + \" - \" + years[-1], sci_name)\n",
    "functions.MapShapefilePolygons(map_these=[shp1, shp2], title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAP Known Range Data Evaluation\n",
    "With all the data in a sqlite database with spatialite capabilities, we can perform the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "os.chdir(codeDir)\n",
    "reload(functions)\n",
    "os.chdir(outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.compile_GAP_presence(eval_id=eval_id, gap_id=gap_id, eval_db=eval_db, cutoff_year=2015, parameters_db=parameters_db,\n",
    "                         outDir=outDir, codeDir=codeDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connr = sqlite3.connect(eval_db)\n",
    "df4 = pd.read_sql_query(sql=\"SELECT strHUC12RNG AS HUC12RNG, \"\n",
    "                                    \"intGAPOrigin AS Origin, intGAPPresence AS Presence, \"\n",
    "                                    \"intGAPReproduction AS Reproduction,\"\n",
    "                                    \"intGAPSeason AS Season, eval_cnt, eval, \"\n",
    "                                    \"validated_presence AS validated_pres FROM sp_range WHERE eval_cnt >=0\", con=connr)\n",
    "df4.set_index([\"HUC12RNG\"], inplace=True)\n",
    "print(\"Tabular results of the evaluation\")\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Mapped results of the evaluation.\")\n",
    "shp3 = {'file': '{0}{1}_eval'.format(outDir, gap_id), 'column': 'eval',\n",
    "        'alias': 'eval', 'column_colors': {1: 'b', 0: 'r'}, \n",
    "        'value_alias': {1:'Agreement', 0:'Disagreement'}, 'drawbounds': False, \n",
    "        'marker': \"s\"}\n",
    "title=\"{0} -- {1}\".format(common_name, eval_id)\n",
    "functions.MapShapefilePolygons(map_these=[shp1, shp3], title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups0 = connr.execute(\"SELECT COUNT(occ_id) FROM evaluation_occurrences GROUP BY geom_xy4326, occurrenceDate;\").fetchall()\n",
    "dups1 = [x[0] for x in dups0]\n",
    "dups2 = [x for x in dups1 if x > 1]\n",
    "print(str(len(dups2)) + ' records were duplicates based on xy coordinate and date-time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After occurrence circles are attributed to HUCs, the results can be recorded in the species' range map table in terms of whether the two data sets agreed and whether they validate the GAP range data for any HUCs. For each evaluation, a column is added for 1) how many records could be attributed to each huc and 2) whether there is agreement at that huc (1 for yes, 0 for no, 'None' for no data for that huc) and 3) whether the GAP range has been validated by the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many records were available in the occurrence database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = connr.execute(\"SELECT COUNT(occ_id) FROM evaluation_occurrences;\").fetchone()[0]\n",
    "print(str(count) + \" occurence records were suitable for this evaluation of the range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of the records were attributable to a HUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hucable = connr.execute(\"SELECT SUM(eval_cnt) FROM sp_range WHERE eval_cnt >=0\").fetchall()[0]\n",
    "print(str(hucable[0]) + \" records were attributable to a HUC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many hucs had records attributed to them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = connr.execute(\"SELECT COUNT(eval_cnt) FROM sp_range WHERE eval_cnt >=0\").fetchall()[0]\n",
    "print(str(containers[0]) + \" HUCs 'contained' records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many records were not used because of the minimum count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = connr.execute(\"SELECT SUM(eval_cnt) FROM sp_range WHERE eval_cnt < ?\", (min_count,)).fetchall()[0]\n",
    "if ones[0] != None:\n",
    "    print(str(ones[0]) + \" HUCs had occurrences but were not validated because they didn't meet the minimum.\")\n",
    "else:\n",
    "    print(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many HUCs were validated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated = connr.execute(\"SELECT COUNT(validated_presence) FROM sp_range WHERE eval = 1\").fetchall()[0]\n",
    "print(str(validated[0]) + \" HUCs were validated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many HUCs did GAP appear to omit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = connr.execute(\"SELECT COUNT(eval) FROM sp_range WHERE eval = 0\".format(eval_id)).fetchall()[0]\n",
    "print(str(missed[0]) + \" HUCs were missed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What was the maximum number of occurrences attributable to a single HUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = connr.execute(\"SELECT MAX(eval_cnt) FROM sp_range\").fetchall()[0]\n",
    "print(\"The maximum number of records attributed to a HUC was \" + str(maxi[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = datetime.now()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "This is just a starting point that needs scrutiny.  It is currently hard-coded for a single species, so deploying it would require redesigning to accomodate large numbers of species, multiple users, many more occurrence records, optimal methods for evaluation and range delineation among other things.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
