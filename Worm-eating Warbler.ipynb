{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of a GAP Range Map Evaluation Framework\n",
    "This notebook details a framework for evaluating GAP range maps with occurrence data retrieved from databases such as GBIF via APIs.  It details the major steps and features of the framework for a single species: the yellow-billed cuckoo.  The primary results are some maps for visualization, columns added to a GAP range data .csv file that is downloaded from ScienceBase, and documentation of decisions and archiving of data used. \n",
    "\n",
    "See the README.md file in this repository for more information.\n",
    "\n",
    "There are a few major steps:  \n",
    "\n",
    "### 1. Range Evaluation Parameter Database\n",
    "This process requires some decision making about how to filter the records and other things.  Such decisions are documented in a database that can be queried in the other steps and referred to later for reference.\n",
    "\n",
    "### 2. Species Concepts\n",
    "Taxonomic classifications are periodically revised,  creating the potential for disagreement among organizations/efforts/databases about what a species name actually refers to.  That disagreement needs to be assessed and resolved before retrievals of occurrence records can be fully trusted.\n",
    "\n",
    "### 3. Retrieve and Filter Species Occurrence Records\n",
    "Occurrence records can be accessed through API's, filtered, and saved in a database.  Filtering can happen during the request for records or after they have been received, but occur before the records are stored in a local database in this framework.  The precision of occurrence records varies due to coordinate uncertainty and detection distances, so points must be represented as circles (i.e., buffered)\n",
    "\n",
    "### 4. Evaluate GAP Known Range Data\n",
    "GAP ranges exist in table form in a database and on ScienceBase.  Ranges can be compared to occurrence circles to find HUCs where GAP was correct about species' presence and where it was wrong about absence.  The results of those comparisons can be saved in columns in the range tables.\n",
    "\n",
    "### 5. Characterize the Occurrence Records Used\n",
    "The documentation performed during data retrieval and filtering and range evaluation provides details on the data that went into the evaluation.\n",
    "\n",
    "### BONUS -- Automated Range Delineation\n",
    "The occurrence record database populated for range evaluation could also be a source for range delineation: either by an expert or with an automated process.  Spatialite has a concave hull function that can be deployed.  I generated seasonal, yearly, and monthly range maps with that process, but they were of poor quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Setup\n",
    "Some parameters need to be declared, including a unique name for this evaluation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pprint\n",
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "pd.set_option('display.width', 600)\n",
    "pd.set_option('display.max_colwidth', 60)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from IPython.display import Image\n",
    "import config\n",
    "import repo_functions as functions\n",
    "from pygbif import occurrences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gap_id = 'bwewax'\n",
    "species_id = 'bwewax0'\n",
    "inDir = '/users/nmtarr/documents/ranges/inputs/'\n",
    "outDir = '/users/nmtarr/documents/ranges/outputs/'\n",
    "summary_name = 'wormie' # an short, memorable name to use for file names etc.\n",
    "years = '2014-2019'\n",
    "eval_id = 'eval_gbif1'\n",
    "request_id = 'GBIFr16'\n",
    "filter_id = 'GBIFf4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Range Evaluation Parameter Database\n",
    "\n",
    "Descriptions of all the columns in the databse are listed below.  As more filtering parameters are explored and employed for each data source, they will need to be described.  The database is currently stored locally but would eventually need to be on a server.\n",
    "\n",
    "The database description and schema is printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntable_names = cursorjup.execute(\"SELECT DISTINCT table_name FROM column_descriptions;\").fetchall()\\nfor table in table_names:\\n    table = table[0]\\n    tbl_desc = cursorjup.execute(\"SELECT description FROM table_descriptions WHERE table_name=\\'{0}\\';\".format(table)).fetchone()\\n    print(\"\\n\",\"-\"*80,\"\\n\\n\",table.upper(),\"TABLE\\n\",str(tbl_desc[0]),\"\\n\")\\n    print(\" COLUMNS\")\\n    print(\" Id, Column Name, Data Type, Not Null, Default, Unique\")\\n    pprint.pprint(cursorjup.execute(\"PRAGMA table_info(\\'{0}\\');\".format(table)).fetchall())\\n    df = cursorjup.execute(\"SELECT * FROM column_descriptions WHERE table_name=\\'{0}\\'\".format(table)).fetchall()\\n    for row in df:\\n        print(\\'\\n\\' + row[1] + \\' -- \\' + row[2])\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connjup = sqlite3.connect('/users/nmtarr/code/occurrence-record-wrangler/parameters.sqlite')\n",
    "cursorjup = connjup.cursor()\n",
    "\"\"\"\n",
    "table_names = cursorjup.execute(\"SELECT DISTINCT table_name FROM column_descriptions;\").fetchall()\n",
    "for table in table_names:\n",
    "    table = table[0]\n",
    "    tbl_desc = cursorjup.execute(\"SELECT description FROM table_descriptions WHERE table_name='{0}';\".format(table)).fetchone()\n",
    "    print(\"\\n\",\"-\"*80,\"\\n\\n\",table.upper(),\"TABLE\\n\",str(tbl_desc[0]),\"\\n\")\n",
    "    print(\" COLUMNS\")\n",
    "    print(\" Id, Column Name, Data Type, Not Null, Default, Unique\")\n",
    "    pprint.pprint(cursorjup.execute(\"PRAGMA table_info('{0}');\".format(table)).fetchall())\n",
    "    df = cursorjup.execute(\"SELECT * FROM column_descriptions WHERE table_name='{0}'\".format(table)).fetchall()\n",
    "    for row in df:\n",
    "        print('\\n' + row[1] + ' -- ' + row[2])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Species Concepts\n",
    "Species concepts of interest need to be matched up with concepts used by data sources.  The BCB's Taxa Information Registry can likely facilitate this in the future.  The species concept lists used here will be saved in the parameters database.  For development purposes, I have manually entered one species but this step can be developed more fully later.\n",
    "\n",
    "Note the field for species geometry that could be used to apply a spatial filter to records that would exclude records that are in far-off or impossible locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 'id_species_concepts.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'species_id': ('bwewax0',\n",
      "                '',\n",
      "                'bwewax',\n",
      "                '726195',\n",
      "                '2489603',\n",
      "                None,\n",
      "                'worm-eating warbler',\n",
      "                'Helmitheros vermivorum',\n",
      "                2003,\n",
      "                None,\n",
      "                None,\n",
      "                200,\n",
      "                1,\n",
      "                20,\n",
      "                '1',\n",
      "                '5,6,7',\n",
      "                '10,11,12,1,2',\n",
      "                'Species name changed from vermivorus in 2003.  Breeding and '\n",
      "                'wintering months from Birds of North America Database (July '\n",
      "                '26, 2019).  Migration is possible in early May and late July. '\n",
      "                'N. Tarr 26 July 2019.')}\n"
     ]
    }
   ],
   "source": [
    "vals = cursorjup.execute(\"SELECT * FROM species_concepts WHERE species_id = '{0}';\".format(species_id)).fetchall()\n",
    "cols = [x[1] for x in cursorjup.execute(\"PRAGMA table_info('species_concepts')\").fetchall()]\n",
    "pprint.pprint(dict(zip(cols, vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retrieve and Filter Occurrence Data\n",
    "Data can be retrieved through APIs, but it needs to be filtered.  Many options for filtering exist and are data source specific, so decisions have to be made about how to filter.  In this framework, I am proposing that filters be treated as unique entities (__filter sets__) that are stored and documented in the rng_eval_params database.  Doing so provides a way to link data sets used for range evaluation (or delineation) back to the decisions made when aquiring them.  Filter sets would be documented in tables specific to the data source and step of filtering; so far, gbif_requests and gbif_filters are such tables.  This example is using filter sets __'r001'__ (request filter) and __'f001'__ (post-request filter).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST FILTER SET\n",
      "request_id                     GBIFr16\n",
      "source                            GBIF\n",
      "lat_range                        27,41\n",
      "lon_range                      -91,-75\n",
      "years_range                  2014,2019\n",
      "months_range                      1,12\n",
      "geoissue                         False\n",
      "coordinate                        True\n",
      "continent                         None\n",
      "creator                        N. Tarr\n",
      "notes           From the last 5 years.\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_sql_query(sql=\"SELECT * FROM gbif_requests WHERE request_id = '{0}'\".format(request_id), con=connjup)\n",
    "print(\"REQUEST FILTER SET\")\n",
    "print(df1.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST REQUEST FILTER SET\n",
      "filter_id                                                                          GBIFf4\n",
      "dataset                                                                              GBIF\n",
      "collection_codes_omit                                                                None\n",
      "institutions_omit                                                                    None\n",
      "has_coordinate_uncertainty                                                              0\n",
      "max_coordinate_uncertainty                                                           5000\n",
      "bases_omit                                            PRESERVED_SPECIMEN, FOSSIL_SPECIMEN\n",
      "protocols_omit                                                                       None\n",
      "sampling_protocols_omit                                                              None\n",
      "issues_omit                   GEODETIC_DATUM_INVALID, INDIVIDUAL_COUNT_INVALID, MULTIM...\n",
      "creator                                                                           N. Tarr\n",
      "notes                                                                                None\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_sql_query(sql=\"SELECT * FROM gbif_filters WHERE filter_id = '{}'\".format(filter_id), con=connjup)\n",
    "print(\"POST REQUEST FILTER SET\")\n",
    "print(df2.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT gbif_id, common_name, scientific_name,\n",
      "                    detection_distance_meters, gap_id\n",
      "             FROM species_concepts\n",
      "             WHERE species_id = 'bwewax0';\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Code/GAP-range-evaluation/retrieve_occurrences.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m              WHERE species_id = '{0}';\"\"\".format(config.sp_id)\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_tax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mconcept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_tax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mgbif_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mcommon_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Run a script that retrieves and filters\n",
    "%run 'retrieve_occurrences.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, records have been retrieved, filtered, buffered, and stored in a database.  They are displayed below on a map with the GAP range map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_range2 = \"{0}{1}_range_4326\".format(inDir, gap_id)\n",
    "\n",
    "shp1 = {'file': gap_range2, 'column': None, 'alias': 'GAP range map',\n",
    "        'drawbounds': False, 'linewidth': .5, 'linecolor': 'y',\n",
    "        'fillcolor': 'y', 'marker':'s'}\n",
    "\n",
    "shp2 = {'file': '{0}{1}_circles'.format(outDir, summary_name), 'column': None,\n",
    "        'alias': 'Occurrence records', 'drawbounds': True, 'linewidth': .75, 'linecolor': 'k',\n",
    "        'fillcolor': None, 'marker':'o'}\n",
    "\n",
    "# Display occurrence polygons\n",
    "title=\"Worm-eating Warbler ({0})\".format(years)\n",
    "functions.MapShapefilePolygons(map_these=[shp1, shp2], title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate GAP Known Range Data\n",
    "The first step in using occurrence records to evaluate GAP range is to build another database to hold the GAP 12 digit HUCs and range for the species, as well as for performing the necessary spatial queries.  The GAP range is retrieved from ScienceBase and the HUCs would be too if they were available as a shapefile.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 'make_range_evaluation_db.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the filter sets, parameters for evaluation have to be set/decided upon.  I am proposing that evaluation parameter sets also be documented as unique entities in a database (i.e, rng_eval_params).  Each evaluation can be given a unique id that can be used in documentation, file naming, and for the names of the columns that will be added to the GAP range table to record the results of the evaluation.  In this example, the evaluation_id is __eval_gbif1__.  It's definition is printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_sql_query(sql=\"SELECT * FROM evaluations WHERE evaluation_id = 'eval_gbif1'\", con=connjup)\n",
    "df3.loc[0, 'years'] = df3.loc[0, 'years'][0:4] + '-' + df3.loc[0, 'years'][-4:]\n",
    "print(\"\\nEVALUATION PARAMETERS\")\n",
    "print(df3.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, buffered occurrence point circles can be spatially compared against the HUC layer in order to determine which HUCs they can be attributed to.  After they are attributed to HUCs, the results can be recorded in the species' range map table in terms of whether the two data sets agreed and whether they validate the GAP range data for any HUCs.  \n",
    "\n",
    "For each evaluation, a column is added for 1) how many records could be attributed to each huc and 2) whether there is agreement at that huc (1 for yes, 0 for no, 'None' for no data for that huc) and 3) whether the GAP range has been validated by the evaluation.\n",
    "\n",
    "Evaluations are unique entities composed of filtered data and evaluation methods and parameters.  For this example, the method used was intersection with an error tolerance of 40% during the intersection.  That means that an occurrence was attributed to a HUC when > 60% of the occurrence circle occurred in the HUC.  The figure below illustrates how this plays out: circles are occurrence polygons, blue polygons are hucs, and numbers tell how many occurrences were attributed to the huc.  Note that that huc with 3 occurrences contains 3 small occurrence circles that are identical and therefore appear as one.  A \"min_count\" is applied in the evaluation too so that HUCs with a number of occurrences > than the min_count are considered to indicate agreement.  This is a way to mediate the influence of false positives and other sporadic errors.  min_counts can be set at the species level or evaluation level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The 'proportion in polygon method' illustrated\")\n",
    "Image(\"/users/nmtarr/Documents/RANGES/Fig1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 'eval_gbif1.py'\n",
    "connr = sqlite3.connect('/users/nmtarr/documents/ranges/outputs/bybcux_range.sqlite')\n",
    "df4 = pd.read_sql_query(sql=\"SELECT strHUC12RNG AS HUC12RNG, \"\n",
    "                                    \"intGAPOrigin AS Origin, intGAPPresence AS Presence, \"\n",
    "                                    \"intGAPReproduction AS Reproduction,\"\n",
    "                                    \"intGAPSeason AS Season, eval_gbif1_cnt, eval_gbif1, \"\n",
    "                                    \"validated_presence AS validated_pres FROM new_range WHERE eval_gbif1_cnt >=0\", con=connr)\n",
    "df4.set_index([\"HUC12RNG\"], inplace=True)\n",
    "print(\"Tabular results of the evaluation\")\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Mapped results of the evaluation.\")\n",
    "shp3 = {'file': '{0}{1}_eval_gbif1'.format(outDir, gap_id), 'column': 'eval_gbif1',\n",
    "        'alias': 'eval_gbif1', 'column_colors': {1: 'b', 0: 'r'}, \n",
    "        'value_alias': {1:'Agreement', 0:'Disagreement'}, 'drawbounds': False, \n",
    "        'marker': \"s\"}\n",
    "title=\"Yellow-billed Cuckoo -- eval_gbif1\"\n",
    "functions.MapShapefilePolygons(map_these=[shp1, shp3], title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Characterize the Occurrence Records Used\n",
    "With the documentation created in the previous steps, we can describe the data used in the evaluation (__eval_gbif1__).  The questions answered below characterize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where were records retrieved from for the evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = cursorjup.execute(\"SELECT table_name FROM table_descriptions\").fetchall()\n",
    "tables = [x[0] for x in tables]\n",
    "\n",
    "filter_sets = cursorjup.execute(\"SELECT filter_sets FROM evaluations WHERE evaluation_id = 'eval_gbif1'\").fetchone()[0]\n",
    "filter_sets = filter_sets.split(\",\")\n",
    "\n",
    "sources = []\n",
    "for s in filter_sets:\n",
    "    s = s.strip()\n",
    "    for tab in tables:\n",
    "        columns = cursorjup.execute(\"SELECT column_name FROM column_descriptions WHERE table_name = '{0}'\".format(tab)).fetchall()\n",
    "        columns = [x[0] for x in columns]\n",
    "        for col in columns:\n",
    "            try:\n",
    "                a = cursorjup.execute(\"SELECT source FROM {1} WHERE {2} = '{0}'\".format(s, tab, col)).fetchone()[0]\n",
    "                sources.append(a)\n",
    "            except:\n",
    "                pass\n",
    "print(list(set(sources))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What was the filtering criteria for the data used in the evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_sets = cursorjup.execute(\"SELECT filter_sets FROM evaluations WHERE evaluation_id = 'eval_gbif1'\").fetchone()[0]\n",
    "filter_sets = filter_sets.split(\",\")\n",
    "\n",
    "tables = cursorjup.execute(\"SELECT table_name FROM table_descriptions\").fetchall()\n",
    "tables = [x[0] for x in tables]\n",
    "\n",
    "for s in filter_sets:\n",
    "    s = s.strip()\n",
    "    for tab in tables:\n",
    "        columns = cursorjup.execute(\"SELECT column_name FROM column_descriptions WHERE table_name = '{0}'\".format(tab)).fetchall()\n",
    "        columns=[x[0] for x in columns]   \n",
    "        for col in columns:\n",
    "            try:\n",
    "                df1 = pd.read_sql_query(sql=\"SELECT * FROM {0} WHERE {1} = '{2}'\".format(tab, col, s), con=connjup)\n",
    "                print(df1.iloc[0]) \n",
    "                print('\\n')\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many records made it through the filters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_occ= sqlite3.connect(outDir + species_id + \"_occurrences.sqlite\")\n",
    "curs_occ = conn_occ.cursor()\n",
    "record_count = curs_occ.execute(\"SELECT COUNT(occ_id) FROM occurrences WHERE species_id = '{0}'\".format(species_id)).fetchone()\n",
    "print(str(record_count[0]) + \" records made it through the filters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What years were represented in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_years = [int(x[0]) for x in curs_occ.execute(\"SELECT strftime('%Y', occurrenceDate) FROM occurrences\").fetchall()]\n",
    "plt.hist(occ_years, bins=20)\n",
    "plt.ylabel(\"number of occurrences\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.title(\"Occurrences per Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What months were represented in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_months = [int(x[0]) for x in curs_occ.execute(\"SELECT strftime('%m', occurrenceDate) FROM occurrences\").fetchall()]\n",
    "plt.hist(occ_months, bins=range(1, 14), color=\"g\")\n",
    "plt.ylabel(\"number of occurrences\")\n",
    "plt.xlabel(\"month\")\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title(\"Occurrences per Month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What issues were present in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn_occ= sqlite3.connect(outDir + species_id + \"_occurrences.sqlite\")\n",
    "curs_occ = conn_occ.cursor()\n",
    "occ_ids = [x[0] for x in curs_occ.execute(\"SELECT occ_id FROM occurrences\").fetchall()]\n",
    "issues = set([])\n",
    "for id in occ_ids:\n",
    "    occdict = occurrences.get(key=id)\n",
    "    issues = issues | set(occdict['issues'])\n",
    "for x in list(issues):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What were the bases of the records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "occ_ids = [x[0] for x in curs_occ.execute(\"SELECT occ_id FROM occurrences\").fetchall()]\n",
    "bases = []\n",
    "for id in occ_ids:\n",
    "    occdict = occurrences.get(key=id)\n",
    "    BOR = occdict['basisOfRecord']\n",
    "    if BOR == \"\" or BOR == None:\n",
    "        bases.append(\"UNKNOWN\")\n",
    "    else:\n",
    "        bases.append(BOR)\n",
    "for x in list(set(bases)):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who provided the records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "occ_ids = [x[0] for x in curs_occ.execute(\"SELECT occ_id FROM occurrences\").fetchall()]\n",
    "by = []\n",
    "for id in occ_ids:\n",
    "    occdict = occurrences.get(key=id)\n",
    "    try:\n",
    "        who = occdict['institutionID']\n",
    "        by.append(who)\n",
    "    except:\n",
    "        who = occdict['institutionCode']\n",
    "        by.append(who)\n",
    "for x in list(set(by)):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Were there duplicate records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups0 = curs_occ.execute(\"SELECT COUNT(occ_id) FROM occurrences GROUP BY geom_xy4326, occurrenceDate;\").fetchall()\n",
    "dups1 = [x[0] for x in dups0]\n",
    "dups2 = [x for x in dups1 if x > 1]\n",
    "print(str(len(dups2)) + ' records were duplicates based on xy coordinate and date-time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What were the evaluation parameters?\n",
    "This answer is repeated from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_sql_query(sql=\"SELECT * FROM evaluations WHERE evaluation_id = 'eval_gbif1'\", con=connjup)\n",
    "df3.loc[0, 'years'] = df3.loc[0, 'years'][0:4] + '-' + df3.loc[0, 'years'][-4:]\n",
    "print(df3.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of the records were attributable to a HUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hucable = curs_rng.execute(\"SELECT SUM(eval_gbif1_cnt) FROM new_range WHERE eval_gbif1_cnt >=0\").fetchall()[0]\n",
    "print(str(hucable[0]) + \" records were attributable to a HUC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many hucs had records attributed to them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = curs_rng.execute(\"SELECT COUNT(eval_gbif1_cnt) FROM new_range WHERE {0}_cnt >=0\".format(eval_id)).fetchall()[0]\n",
    "print(str(containers[0]) + \" HUCs 'contained' records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many records were not used because of the minimum count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_rng = sqlite3.connect(outDir + gap_id + '_range.sqlite')\n",
    "curs_rng = conn_rng.cursor()\n",
    "ones = curs_rng.execute(\"SELECT SUM(eval_gbif1_cnt) FROM new_range WHERE eval_gbif1_cnt = 1\").fetchall()[0]\n",
    "print(str(ones[0]) + \" HUCs had occurrences but were not validated because they didn't meet the minimum.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many HUCs were validated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated = curs_rng.execute(\"SELECT COUNT(eval_gbif1) FROM new_range WHERE {0} = 1\".format(eval_id)).fetchall()[0]\n",
    "print(str(validated[0]) + \" HUCs were validated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many HUCs did GAP appear to omit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = curs_rng.execute(\"SELECT COUNT(eval_gbif1) FROM new_range WHERE {0} = 0\".format(eval_id)).fetchall()[0]\n",
    "print(str(missed[0]) + \" HUCs were missed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What was the maximum number of occurrences attributable to a single HUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = curs_rng.execute(\"SELECT MAX(eval_gbif1_cnt) FROM new_range\").fetchall()[0]\n",
    "print(\"The maximum number of records attributed to a HUC was \" + str(maxi[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS -- Automated Range Delineation\n",
    "I generated yearly, monthly, and seasonal ranges for the yellow-billed cuckoo with spatialite's concave hull function.  Each map was stored as a record in a table (with geometry) within range evaluation database (for now).  Below is an example of a summer range map.  It does not appear useful but maybe the delineation method could be improved or integrating more occurrence records will improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 'make_range_polygons.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shp4 = {'file': '{0}summer_range'.format(outDir, gap_id), 'column': None,\n",
    "        'alias': 'Concave hull', 'drawbounds': True, 'linewidth': 2., 'linecolor': 'k',\n",
    "        'fillcolor': None, 'marker':'s'}\n",
    "\n",
    "shp5 = {'file': '{0}summer_occs'.format(outDir, gap_id), 'column': None,\n",
    "        'alias': 'Summer records', 'drawbounds': True, 'linewidth': 2., 'linecolor': 'r',\n",
    "        'fillcolor': None, 'marker':'o'}\n",
    "\n",
    "# Display occurrence polygons\n",
    "title=\"Yellow-billed Cuckoo Summer Range ({0})\".format(years)\n",
    "functions.MapShapefilePolygons(map_these=[shp1, shp4, shp5], title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "This is just a starting point that needs scrutiny.  It is currently hard-coded for a single species, so deploying it would require redesigning to accomodate large numbers of species, multiple users, many more occurrence records, optimal methods for evaluation and range delineation among other things.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
